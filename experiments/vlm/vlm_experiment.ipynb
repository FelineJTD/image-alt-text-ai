{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hNHIJYRWq1bh"
   },
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "qQ9GsCzCq1bi"
   },
   "outputs": [],
   "source": [
    "NUMBER_OF_IMAGES=600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "-DLrh6fFq1bi"
   },
   "outputs": [],
   "source": [
    "OPENAI_API_KEY=\"\"\n",
    "HUGGINGFACE_API_KEY=\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NkLTFD2Sq1bj"
   },
   "source": [
    "# Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "MBh40Ks2q1bj"
   },
   "outputs": [],
   "source": [
    "role_identifier_prompt = \"\"\"\n",
    "You are part of a team tasked with generating role-aware and context-aware image alt texts for images on websites. Your role is to identify the role of the given image in the website according to the definitions provided by the WCAG Web Accessibility Initiative (WAI) outlined below.\n",
    "\n",
    "\n",
    "- informative: Images that graphically represent concepts and information, typically pictures, photos, and illustrations. The text alternative should be at least a short description conveying the essential information presented by the image.\n",
    "\n",
    "- decorative: The only purpose of an image is to add visual decoration to the page, rather than to convey information that is important to understanding the page. This includes images that are considered eye candy or used for visual effect. Classify the image to decorative if having a null alt-text (alt=\"\") will not result in any loss of information.\n",
    "\n",
    "- functional: Images used as a link or as a button, which carry a functionality to the page. Examples of such images are a printer icon to represent the print function or a button to submit a form. The alt text should describe the functionality of the link or button rather than the visual image.\n",
    "\n",
    "- complex: Images used to convey data or detailed information, such as graphs or charts. Alt texts provide a complete text equivalent of the data or information provided in the image as the text alternative.\n",
    "\n",
    "\n",
    "As each role needs to be handled differently when generating alt texts, your output will be used to help another team member write the most suitable alt text that is role-aware and contex-aware for the image to help create more accessible websites.\n",
    "\n",
    "Return only the role of the image from the list above. Return the role as a single word without any enclosing bracket or other punctuations (informative, decorative, functional, text, or complex). THIS IS IMPORTANT! RETURN ONLY THE ROLE OF THE IMAGE.\n",
    "\n",
    "Here is the detail about the image: \n",
    "{message}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-shot\n",
    "role_identifier_prompt = \"\"\"\n",
    "You are part of a team tasked with generating role-aware and context-aware image alt texts for images on websites. Your role is to identify the role of the given image in the website according to the definitions provided by the WCAG Web Accessibility Initiative (WAI) outlined below.\n",
    "\n",
    "\n",
    "- informative: Images that graphically represent concepts and information, typically pictures, photos, and illustrations. The text alternative should be at least a short description conveying the essential information presented by the image.\n",
    "\n",
    "- decorative: The only purpose of an image is to add visual decoration to the page, rather than to convey information that is important to understanding the page. This includes images that are considered eye candy or used for visual effect. Classify the image to decorative if having a null alt-text (alt=\"\") will not result in any loss of information.\n",
    "\n",
    "- functional: Images used as a link or as a button, which carry a functionality to the page. Examples of such images are a printer icon to represent the print function or a button to submit a form. The alt text should describe the functionality of the link or button rather than the visual image.\n",
    "\n",
    "- complex: Images used to convey data or detailed information, such as graphs or charts. Alt texts provide a complete text equivalent of the data or information provided in the image as the text alternative.\n",
    "\n",
    "\n",
    "Example:\n",
    "You are given an image of a dog wearing a bell, with the following context:\n",
    "The image's attributes: {\n",
    "      \"class\": [\"img\"],\n",
    "      \"id\": \"dog-off-duty\",\n",
    "      \"src\": \"\",\n",
    "      \"alt\": \"\"\n",
    "    }\n",
    "The image's <a> or <button> parent: None\n",
    "The previous text before the image appears: None\n",
    "The next text after the image appears: Off-duty guide dogs often wear a bell. Its ring helps the blind owner keep track of the dog's location\n",
    "\n",
    "In this case, you should output \"informative\" as the image is a picture of a dog wearing a bell, which is essential information for the reader to understand the context of the text.\n",
    "\n",
    "\n",
    "As each role needs to be handled differently when generating alt texts, your output will be used to help another team member write the most suitable alt text that is role-aware and contex-aware for the image to help create more accessible websites.\n",
    "\n",
    "Return only the role of the image from the list above. Return the role as a single word without any enclosing bracket or other punctuations (informative, decorative, functional, text, or complex). THIS IS IMPORTANT! RETURN ONLY THE ROLE OF THE IMAGE.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Few-shot\n",
    "role_identifier_prompt = \"\"\"\n",
    "You are part of a team tasked with generating role-aware and context-aware image alt texts for images on websites. Your role is to identify the role of the given image in the website according to the definitions provided by the WCAG Web Accessibility Initiative (WAI) outlined below.\n",
    "\n",
    "\n",
    "- informative: Images that graphically represent concepts and information, typically pictures, photos, and illustrations. The text alternative should be at least a short description conveying the essential information presented by the image.\n",
    "\n",
    "- decorative: The only purpose of an image is to add visual decoration to the page, rather than to convey information that is important to understanding the page. This includes images that are considered eye candy or used for visual effect. Classify the image to decorative if having a null alt-text (alt=\"\") will not result in any loss of information.\n",
    "\n",
    "- functional: Images used as a link or as a button, which carry a functionality to the page. Examples of such images are a printer icon to represent the print function or a button to submit a form. The alt text should describe the functionality of the link or button rather than the visual image.\n",
    "\n",
    "- complex: Images used to convey data or detailed information, such as graphs or charts. Alt texts provide a complete text equivalent of the data or information provided in the image as the text alternative.\n",
    "\n",
    "\n",
    "Example 1:\n",
    "You are given an image of a dog wearing a bell, with the following context:\n",
    "The image's attributes: {\n",
    "    \"class\": [\"img\"],\n",
    "    \"id\": \"dog-off-duty\",\n",
    "    \"src\": \"\",\n",
    "    \"alt\": \"\"\n",
    "}\n",
    "The image's <a> or <button> parent: None\n",
    "The previous text before the image appears: None\n",
    "The next text after the image appears: Off-duty guide dogs often wear a bell. Its ring helps the blind owner keep track of the dog's location\n",
    "\n",
    "In this case, you should output \"informative\" as the image is a picture of a dog wearing a bell, which is essential information for the reader to understand the context of the text.\n",
    "\n",
    "Example 2:\n",
    "You are given a logo image of RealPage, Inc., with the following context:\n",
    "The image's attributes: {\n",
    "    \"src\": \"/TemplateResources/Global/images/rplogo-white.png\",\n",
    "    \"alt\": \"RealPage, Inc.\"\n",
    "}\n",
    "The image's <a> or <button> parent: \"<a href=\\\"https://www.realpage.com/apartment-marketing/\\\" target=\\\"_blank\\\"><img alt=\\\"RealPage, Inc.\\\" src=\\\"/TemplateResources/Global/images/rplogo-white.png\\\"/></a>\"\n",
    "The previous text before the image appears: address\n",
    "The next text after the image appears: Privacy Preference Center\n",
    "\n",
    "In this case, you should output \"functional\" as the image is a logo used as a link to the RealPage, Inc. website, apparent from the parent <a> tag. If there is no parent <a> or <button> tag, the image would be considered \"informative\" if it provides essential information or \"decorative\" if it is used for visual decoration.\n",
    "\n",
    "\n",
    "Example 3:\n",
    "You are given a stock photo of a busy conference check in desk, with the following context:\n",
    "The image's attributes: {\n",
    "    \"class\": [\"card-img-top\"],\n",
    "}\n",
    "The image's <a> or <button> parent: None\n",
    "The previous text before the image appears: Print delegate badge instantly with fast and delightful experience.\n",
    "The next text after the image appears: Smart Mobile Check-in\n",
    "\n",
    "In this case, you should output \"decorative\" as the image is used for visual decoration and does not convey any essential information, as the previous and next text already describe the relevant context.\n",
    "\n",
    "\n",
    "Example 4:\n",
    "You are given multiple screenshots of a product's user interface in different devices, with the following context:\n",
    "The image's attributes: {\n",
    "    \"width\": \"1024\",\n",
    "    \"height\": \"614\",\n",
    "    \"class\": [\n",
    "        \"attachment-large\",\n",
    "        \"size-large\",\n",
    "        \"wp-image-37835\"\n",
    "    ],\n",
    "    \"sizes\": \"(max-width: 1024px) 100vw, 1024px\"\n",
    "},\n",
    "\"input_a_button_parent\": \"None\",\n",
    "\"input_next_text\": \"Our Company\",\n",
    "\n",
    "In this case, you should output \"complex\" as the image is used to convey detailed information about the product's user interface.\n",
    "\n",
    "\n",
    "As each role needs to be handled differently when generating alt texts, your output will be used to help another team member write the most suitable alt text that is role-aware and contex-aware for the image to help create more accessible websites.\n",
    "\n",
    "Return only the role of the image from the list above. Return the role as a single word without any enclosing bracket or other punctuations (informative, decorative, functional, text, or complex). THIS IS IMPORTANT! RETURN ONLY THE ROLE OF THE IMAGE.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "role_identifier_prompt = \"\"\"\n",
    "You are part of a team tasked with generating role-aware and context-aware image alt texts for images on websites. Your role is to identify the role of the given image in the website according to the definitions provided by the WCAG Web Accessibility Initiative (WAI). Classify the image into \"informative\", \"decorative\", \"functional\", or \"complex\". Return the role as a single word without any enclosing bracket or other punctuations (informative, decorative, functional, text, or complex). THIS IS IMPORTANT! RETURN ONLY THE ROLE OF THE IMAGE.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dbh9onv7q1bk"
   },
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "OnRcAdIMq1bk"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "\n",
    "json_dir = \"../../scraper/output\"\n",
    "\n",
    "filenames = os.listdir(json_dir)\n",
    "\n",
    "# Shuffle the filenames\n",
    "random.seed(42)\n",
    "random.shuffle(filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NzkSgKV7q1bk"
   },
   "source": [
    "# Llama-3.2-11B-Vision-Instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "Jen1MT9Jq1bl"
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import InferenceClient\n",
    "\n",
    "client = InferenceClient(api_key=HUGGINGFACE_API_KEY)\n",
    "\n",
    "def determine_role_llama(image):\n",
    "    image_details = f\"\"\"\n",
    "        The image's attributes: {json.dumps(image[\"attrs\"])}\\n\\n\n",
    "        The image's <a> or <button> parent: {image[\"a_button_parent\"]}\\n\\n\n",
    "        The previous text before the image appears: {image[\"previous_text\"]}\\n\\n\n",
    "        The next text after the image appears: {image[\"next_text\"]}\\n\\n\n",
    "    \"\"\"\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": image[\"src\"]\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": role_identifier_prompt.format(message=image_details)\n",
    "                },\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"meta-llama/Llama-3.2-11B-Vision-Instruct\",\n",
    "        messages=messages,\n",
    "        max_tokens=500\n",
    "    )\n",
    "\n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The World Wide Web Consortium's (W3C) Web Content Accessibility Guidelines (WCAG) 2.1 defines seven image roles to help developers and designers create more accessible web content. These roles are essential for ensuring that all users, including those with visual impairments, can understand and interact with visual content on the web. Here are the seven image roles defined by WCAG:\n",
      "\n",
      "1. **Decorative**: Decorative images are intended to be purely aesthetic and do not provide any information or function. They may be used to add visual interest or style to a website, but they do not enhance the content or provide any assistive information. Decorative images should be hidden or removed from the accessibility tree to prevent them from distracting from the main content. (Example: A patterned background image)\n",
      "\n",
      "2. **Informative**: Informative images provide information that is essential to understanding the content, but the information is not solely contained within the image itself. These images often accompany text or other content, providing additional context or explanations. Informative images should be accessible through alternative text or other means to ensure that users who cannot see them can still understand the information. (Example: A diagram illustrating a process)\n",
      "\n",
      "3. **Functional**: Functional images are buttons, icons, or other image-based controls that are used to initiate an action or interact with the website. Alternative text, color, and other visual cues can be used to make these images more accessible to users with visual impairments. (Example: A \"Login\" button or an \"Add to Cart\" icon)\n",
      "\n",
      "4. **Complex**: Complex images are diagrams, charts, or other illustrations that contain complex or nuanced information. These images may require a long description to be provided in alternative text to help users understand the content. (Example: A detailed flowchart or a graph showing trends)\n",
      "\n",
      "5. **Text**: Text-based images, such as screenshots or logos with text, should be properly formatted as text and follow basic typography principles. The text should also be readable by screen readers and other assistive technologies. (Example: A screenshot with a readable title text or a logo with text)\n",
      "\n",
      "6. **Images of Maps**: Images of maps can range from simple cultural maps to complex topographic maps. They may require a map key, alternate descriptions, or instructions to help users understand the information. (Example: A Google Map displaying a location or a simple map showing different countries)\n",
      "\n",
      "7. **Group Images**: Group images are collections of images, such\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import InferenceClient\n",
    "\n",
    "client = InferenceClient(api_key=HUGGINGFACE_API_KEY)\n",
    "\n",
    "def llama_test():\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"Explain about the 7 image roles defined by WCAG (decorative, informative, functional, complex, text, images of maps, and group images).\"\n",
    "                },\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"meta-llama/Llama-3.2-11B-Vision-Instruct\",\n",
    "        messages=messages,\n",
    "        max_tokens=500\n",
    "    )\n",
    "\n",
    "    return completion.choices[0].message.content\n",
    "\n",
    "print(llama_test())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SmolVLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.1.1 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/home/felinejtd/anaconda3/envs/thesis/lib/python3.12/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/home/felinejtd/anaconda3/envs/thesis/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/home/felinejtd/anaconda3/envs/thesis/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/home/felinejtd/anaconda3/envs/thesis/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/home/felinejtd/anaconda3/envs/thesis/lib/python3.12/asyncio/base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/home/felinejtd/anaconda3/envs/thesis/lib/python3.12/asyncio/base_events.py\", line 1986, in _run_once\n",
      "    handle._run()\n",
      "  File \"/home/felinejtd/anaconda3/envs/thesis/lib/python3.12/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/home/felinejtd/anaconda3/envs/thesis/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/home/felinejtd/anaconda3/envs/thesis/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/home/felinejtd/anaconda3/envs/thesis/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/home/felinejtd/anaconda3/envs/thesis/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/home/felinejtd/anaconda3/envs/thesis/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/home/felinejtd/anaconda3/envs/thesis/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/home/felinejtd/anaconda3/envs/thesis/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/home/felinejtd/anaconda3/envs/thesis/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/home/felinejtd/anaconda3/envs/thesis/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/home/felinejtd/anaconda3/envs/thesis/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/home/felinejtd/anaconda3/envs/thesis/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/home/felinejtd/anaconda3/envs/thesis/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/home/felinejtd/anaconda3/envs/thesis/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_11759/386977465.py\", line 1, in <module>\n",
      "    import torch\n",
      "  File \"/home/felinejtd/anaconda3/envs/thesis/lib/python3.12/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/home/felinejtd/anaconda3/envs/thesis/lib/python3.12/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/home/felinejtd/anaconda3/envs/thesis/lib/python3.12/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/home/felinejtd/anaconda3/envs/thesis/lib/python3.12/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/home/felinejtd/anaconda3/envs/thesis/lib/python3.12/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/home/felinejtd/anaconda3/envs/thesis/lib/python3.12/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The checkpoint you are trying to load has model type `idefics3` but Transformers does not recognize this architecture. This could be because of an issue with the checkpoint, or because your version of Transformers is out of date.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/thesis/lib/python3.12/site-packages/transformers/models/auto/configuration_auto.py:1023\u001b[0m, in \u001b[0;36mAutoConfig.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m   1022\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1023\u001b[0m     config_class \u001b[38;5;241m=\u001b[39m \u001b[43mCONFIG_MAPPING\u001b[49m\u001b[43m[\u001b[49m\u001b[43mconfig_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel_type\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m   1024\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/thesis/lib/python3.12/site-packages/transformers/models/auto/configuration_auto.py:725\u001b[0m, in \u001b[0;36m_LazyConfigMapping.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    724\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mapping:\n\u001b[0;32m--> 725\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[1;32m    726\u001b[0m value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mapping[key]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'idefics3'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Initialize processor and model\u001b[39;00m\n\u001b[1;32m     13\u001b[0m processor \u001b[38;5;241m=\u001b[39m AutoProcessor\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHuggingFaceTB/SmolVLM-Instruct\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 14\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForVision2Seq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHuggingFaceTB/SmolVLM-Instruct\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbfloat16\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Create input messages\u001b[39;00m\n\u001b[1;32m     20\u001b[0m messages \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     21\u001b[0m     {\n\u001b[1;32m     22\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     28\u001b[0m     },\n\u001b[1;32m     29\u001b[0m ]\n",
      "File \u001b[0;32m~/anaconda3/envs/thesis/lib/python3.12/site-packages/transformers/models/auto/auto_factory.py:526\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquantization_config\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    524\u001b[0m     _ \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquantization_config\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 526\u001b[0m config, kwargs \u001b[38;5;241m=\u001b[39m \u001b[43mAutoConfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    528\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_unused_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    529\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    530\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcode_revision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcode_revision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    532\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    533\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    534\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    536\u001b[0m \u001b[38;5;66;03m# if torch_dtype=auto was passed here, ensure to pass it on\u001b[39;00m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs_orig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch_dtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/thesis/lib/python3.12/site-packages/transformers/models/auto/configuration_auto.py:1025\u001b[0m, in \u001b[0;36mAutoConfig.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m   1023\u001b[0m         config_class \u001b[38;5;241m=\u001b[39m CONFIG_MAPPING[config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[1;32m   1024\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m-> 1025\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1026\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe checkpoint you are trying to load has model type `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1027\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut Transformers does not recognize this architecture. This could be because of an \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1028\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124missue with the checkpoint, or because your version of Transformers is out of date.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1029\u001b[0m         )\n\u001b[1;32m   1030\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m config_class\u001b[38;5;241m.\u001b[39mfrom_dict(config_dict, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munused_kwargs)\n\u001b[1;32m   1031\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1032\u001b[0m     \u001b[38;5;66;03m# Fallback: use pattern matching on the string.\u001b[39;00m\n\u001b[1;32m   1033\u001b[0m     \u001b[38;5;66;03m# We go from longer names to shorter names to catch roberta before bert (for instance)\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: The checkpoint you are trying to load has model type `idefics3` but Transformers does not recognize this architecture. This could be because of an issue with the checkpoint, or because your version of Transformers is out of date."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import AutoProcessor, AutoModelForVision2Seq\n",
    "from transformers.image_utils import load_image\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Load images\n",
    "image1 = load_image(\"https://cdn.britannica.com/61/93061-050-99147DCE/Statue-of-Liberty-Island-New-York-Bay.jpg\")\n",
    "image2 = load_image(\"https://huggingface.co/spaces/merve/chameleon-7b/resolve/main/bee.jpg\")\n",
    "\n",
    "# Initialize processor and model\n",
    "processor = AutoProcessor.from_pretrained(\"HuggingFaceTB/SmolVLM-Instruct\")\n",
    "model = AutoModelForVision2Seq.from_pretrained(\n",
    "    \"HuggingFaceTB/SmolVLM-Instruct\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    ").to(DEVICE)\n",
    "\n",
    "# Create input messages\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"image\"},\n",
    "            {\"type\": \"image\"},\n",
    "            {\"type\": \"text\", \"text\": \"Can you describe the two images?\"}\n",
    "        ]\n",
    "    },\n",
    "]\n",
    "\n",
    "# Prepare inputs\n",
    "prompt = processor.apply_chat_template(messages, add_generation_prompt=True)\n",
    "inputs = processor(text=prompt, images=[image1, image2], return_tensors=\"pt\")\n",
    "inputs = inputs.to(DEVICE)\n",
    "\n",
    "# Generate outputs\n",
    "generated_ids = model.generate(**inputs, max_new_tokens=500)\n",
    "generated_texts = processor.batch_decode(\n",
    "    generated_ids,\n",
    "    skip_special_tokens=True,\n",
    ")\n",
    "\n",
    "print(generated_texts[0])\n",
    "\"\"\"\n",
    "Assistant: The first image shows a green statue of the Statue of Liberty standing on a stone pedestal in front of a body of water. \n",
    "The statue is holding a torch in its right hand and a tablet in its left hand. The water is calm and there are no boats or other objects visible. \n",
    "The sky is clear and there are no clouds. The second image shows a bee on a pink flower. \n",
    "The bee is black and yellow and is collecting pollen from the flower. The flower is surrounded by green leaves.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Qwen-7B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import InferenceClient\n",
    "\n",
    "client = InferenceClient(api_key=HUGGINGFACE_API_KEY)\n",
    "\n",
    "def determine_role_qwen_7b(image):\n",
    "    image_details = f\"\"\"\n",
    "        The image's attributes: {json.dumps(image[\"attrs\"])}\\n\\n\n",
    "        The image's <a> or <button> parent: {image[\"a_button_parent\"]}\\n\\n\n",
    "        The previous text before the image appears: {image[\"previous_text\"]}\\n\\n\n",
    "        The next text after the image appears: {image[\"next_text\"]}\\n\\n\n",
    "    \"\"\"\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": image[\"src\"]\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": role_identifier_prompt.format(message=image_details)\n",
    "                },\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"Qwen/Qwen2-VL-7B-Instruct\",\n",
    "        messages=messages,\n",
    "        max_tokens=500\n",
    "    )\n",
    "\n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Web Content Accessibility Guidelines现在很多都用7个imag\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import InferenceClient\n",
    "\n",
    "client = InferenceClient(api_key=HUGGINGFACE_API_KEY)\n",
    "\n",
    "def qwen_test():\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"Explain about the 7 image roles defined by WCAG (decorative, informative, functional, complex, text, images of maps, and group images).\"\n",
    "                },\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"Qwen/Qwen2-VL-7B-Instruct\",\n",
    "        messages=messages,\n",
    "        max_tokens=500\n",
    "    )\n",
    "\n",
    "    return completion.choices[0].message.content\n",
    "\n",
    "print(qwen_test())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sTS2SvHLq1bm"
   },
   "source": [
    "# Qwen-2B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "80eutEpYq1bm"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/felinejtd/anaconda3/envs/thesis/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import InferenceClient\n",
    "\n",
    "client = InferenceClient(api_key=HUGGINGFACE_API_KEY)\n",
    "\n",
    "def determine_role_qwen_2b(image):\n",
    "    image_details = f\"\"\"\n",
    "        The image's attributes: {json.dumps(image[\"attrs\"])}\\n\\n\n",
    "        The image's <a> or <button> parent: {image[\"a_button_parent\"]}\\n\\n\n",
    "        The previous text before the image appears: {image[\"previous_text\"]}\\n\\n\n",
    "        The next text after the image appears: {image[\"next_text\"]}\\n\\n\n",
    "    \"\"\"\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": image[\"src\"]\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": role_identifier_prompt.format(message=image_details)\n",
    "                },\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"Qwen/Qwen2-VL-2B-Instruct\",\n",
    "        messages=messages,\n",
    "        max_tokens=500\n",
    "    )\n",
    "\n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Web Content Accessibility Guidelines or WCAG is a set of recommended practices to ensure that web content is accessible to people with a variety of disabilities including people with physical and visual impairments/access, and people who use assistive technology like screen readers/accessories/additional  language texts in other larger text, and text on demand and data control. The 7 roles of the  are of help with the  the of building a  and to  people with  and and  and  and to ensure that information can be easily and  for people with  and to multiple  and to and when  and . Interpret what each of the and how to of and and  any to and any to build on to and to for and  for and to and to the and design and  and and for the and of and and and and and and and and of and and and and of and and and and and and and and and and and and each when and the and of and and and and for the and of the for of and of for the in and and to and and for the and of and of and is for and to and and and to for and for and and for and for and for and for and for and for and for and for and for and for and for and for and for and for and for and for and for and for and for for and for and for for and for and for and for for and for and for and for and and for and for and for and for and for and for and for and for to and for and for and for and for and for and for and for and for and for and for and for and for and for and for and for to and for and for and for and for and for and for and for and to and for and for and for and for and for and for the and for for and for and for and for and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and for any and for and for and for and for and for for and for and for and and for and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and to and for and for and for and for and for and for and for and for and and for for and for and for\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import InferenceClient\n",
    "\n",
    "client = InferenceClient(api_key=HUGGINGFACE_API_KEY)\n",
    "\n",
    "def qwen_test():\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"Explain about the 7 image roles defined by WCAG (decorative, informative, functional, complex, text, images of maps, and group images).\"\n",
    "                },\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"Qwen/Qwen2-VL-2B-Instruct\",\n",
    "        messages=messages,\n",
    "        max_tokens=500\n",
    "    )\n",
    "\n",
    "    return completion.choices[0].message.content\n",
    "\n",
    "print(qwen_test())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rvb0makVq1bn"
   },
   "source": [
    "# GPT-4o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4crBF-Hkq1bn",
    "outputId": "07740661-6043-44a6-f52f-90f81356626d"
   },
   "outputs": [],
   "source": [
    "# !pip install langchain_openai\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "def determine_role_gpt_4o(image):\n",
    "    image_details = f\"\"\"\n",
    "        The image's attributes: {json.dumps(image[\"attrs\"])}\\n\\n\n",
    "        The image's <a> or <button> parent: {image[\"a_button_parent\"]}\\n\\n\n",
    "        The previous text before the image appears: {image[\"previous_text\"]}\\n\\n\n",
    "        The next text after the image appears: {image[\"next_text\"]}\\n\\n\n",
    "    \"\"\"\n",
    "\n",
    "    role_identifier_llm = ChatOpenAI(model='ft:gpt-4o-2024-08-06:personal:role-iden-50:AahYYJoD', temperature=0.5, api_key=OPENAI_API_KEY)\n",
    "    predicted_role = role_identifier_llm.invoke(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                role_identifier_prompt\n",
    "            ),\n",
    "            (\n",
    "                \"human\",\n",
    "                [\n",
    "                    {\n",
    "                        \"type\": \"image_url\", \"image_url\": {\"url\": image[\"src\"]}\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"text\", \"text\": image_details\n",
    "                    }\n",
    "                ]\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return predicted_role.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Web Content Accessibility Guidelines (WCAG) do not explicitly define \"image roles\" per se, but they do provide guidance on how to make images accessible. This guidance can be interpreted in terms of different roles or purposes that images might serve on a webpage. Here are seven common roles or purposes for images in the context of web accessibility, along with how they should be handled according to WCAG:\n",
      "\n",
      "1. **Informative Images**: These images convey simple information or concepts that can be expressed in a short phrase or sentence. They should have descriptive alternative text (alt text) that conveys the same information as the image.\n",
      "\n",
      "2. **Decorative Images**: These images are used for aesthetic purposes and do not convey any meaningful information. They should have empty alt text (`alt=\"\"`) so that screen readers can skip them.\n",
      "\n",
      "3. **Functional Images**: These images are used as buttons or links and have a functional purpose. The alt text should describe the function or action that will occur when the image is activated (e.g., \"Submit,\" \"Search\").\n",
      "\n",
      "4. **Complex Images**: These include charts, graphs, and diagrams that convey complex information. They should have a detailed text description, either in the alt text or on the page itself, to convey the information contained in the image.\n",
      "\n",
      "5. **Images of Text**: These images contain text that conveys information. It is recommended to use actual text instead of images of text whenever possible. If images of text are used, the alt text should contain the same text as in the image.\n",
      "\n",
      "6. **Group Images**: These are images that are part of a group of images that convey a single piece of information. The group should be described as a whole, and individual images may not need separate alt text unless they contribute additional information.\n",
      "\n",
      "7. **Image Maps**: These images contain multiple clickable areas (hotspots). Each hotspot should have alt text that describes the link or action associated with it.\n",
      "\n",
      "These roles help ensure that images are accessible to users with disabilities, particularly those who rely on screen readers or other assistive technologies. The key is to provide meaningful alternative text that accurately represents the content and function of the image.\n"
     ]
    }
   ],
   "source": [
    "# !pip install langchain_openai\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "def gpt_4o_test():\n",
    "    role_identifier_llm = ChatOpenAI(model='gpt-4o', temperature=0.5, api_key=OPENAI_API_KEY)\n",
    "    predicted_role = role_identifier_llm.invoke(\n",
    "        [\n",
    "            (\n",
    "                \"human\",\n",
    "                [\n",
    "                    {\n",
    "                        \"type\": \"text\", \"text\": \"Tell me the 7 image roles defined by WCAG.\"\n",
    "                    }\n",
    "                ]\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return predicted_role.content\n",
    "\n",
    "print(gpt_4o_test())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QN-2DldLq1bn"
   },
   "source": [
    "# GPT-4o-mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "jgBt90gqq1bn"
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "def determine_role_gpt_4o_mini(image):\n",
    "    image_details = f\"\"\"\n",
    "        The image's attributes: {json.dumps(image[\"attrs\"])}\\n\\n\n",
    "        The image's <a> or <button> parent: {image[\"a_button_parent\"]}\\n\\n\n",
    "        The previous text before the image appears: {image[\"previous_text\"]}\\n\\n\n",
    "        The next text after the image appears: {image[\"next_text\"]}\\n\\n\n",
    "    \"\"\"\n",
    "\n",
    "    role_identifier_llm = ChatOpenAI(model='gpt-4o-mini', temperature=0.5, api_key=OPENAI_API_KEY)\n",
    "    predicted_role = role_identifier_llm.invoke(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                role_identifier_prompt\n",
    "            ),\n",
    "            (\n",
    "                \"human\",\n",
    "                [\n",
    "                    {\n",
    "                        \"type\": \"image_url\", \"image_url\": {\"url\": image[\"src\"]}\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"text\", \"text\": image_details\n",
    "                    }\n",
    "                ]\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return predicted_role.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Web Content Accessibility Guidelines (WCAG) define several roles for images to ensure that they are accessible to all users, including those with disabilities. The seven image roles defined by WCAG are:\n",
      "\n",
      "1. **Decorative Images**: These images are purely for decorative purposes and do not convey any meaningful content. They should have an empty `alt` attribute (e.g., `alt=\"\"`) so that screen readers can skip them.\n",
      "\n",
      "2. **Informative Images**: These images convey information that is essential to understanding the content. They should have a descriptive `alt` attribute that conveys the meaning of the image.\n",
      "\n",
      "3. **Functional Images**: These images are used as links or buttons (e.g., icons). They should have an `alt` attribute that describes the function of the image (e.g., \"Search\" for a magnifying glass icon).\n",
      "\n",
      "4. **Textual Images**: These images contain text that is important for understanding the content. They should be accompanied by an `alt` attribute that describes the text or the message conveyed by the image.\n",
      "\n",
      "5. **Complex Images**: These images include charts, graphs, or infographics that convey complex information. They should have a detailed description, often provided in a separate text alternative, so that users can understand the content.\n",
      "\n",
      "6. **Image Maps**: These are images with clickable areas that link to different destinations. Each area should have a descriptive `alt` attribute that explains its purpose.\n",
      "\n",
      "7. **Background Images**: These images are used purely for visual styling and do not convey any content. They should be implemented in CSS rather than HTML, and they do not require an `alt` attribute.\n",
      "\n",
      "Understanding these roles helps web developers and content creators provide appropriate text alternatives for images, ensuring that all users can access the information presented on the web.\n"
     ]
    }
   ],
   "source": [
    "# !pip install langchain_openai\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "def gpt_4o_mini_test():\n",
    "    role_identifier_llm = ChatOpenAI(model='gpt-4o-mini', temperature=0.5, api_key=OPENAI_API_KEY)\n",
    "    predicted_role = role_identifier_llm.invoke(\n",
    "        [\n",
    "            (\n",
    "                \"human\",\n",
    "                [\n",
    "                    {\n",
    "                        \"type\": \"text\", \"text\": \"Tell me the 7 image roles defined by WCAG.\"\n",
    "                    }\n",
    "                ]\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return predicted_role.content\n",
    "\n",
    "print(gpt_4o_mini_test())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GEP_XKAWq1bo"
   },
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "HcCD7cTAq1bo"
   },
   "outputs": [],
   "source": [
    "def calculate_scores(results):\n",
    "    scores = {\n",
    "        \"llama\": {\n",
    "            \"whole_accuracy\": 0,\n",
    "            \"precision\": {},\n",
    "            \"recall\": {},\n",
    "            \"f1\": {},\n",
    "        },\n",
    "        \"gpt-4o\": {\n",
    "            \"whole_accuracy\": 0,\n",
    "            \"precision\": {},\n",
    "            \"recall\": {},\n",
    "            \"f1\": {},\n",
    "        },\n",
    "        \"gpt-4o-mini\": {\n",
    "            \"whole_accuracy\": 0,\n",
    "            \"precision\": {},\n",
    "            \"recall\": {},\n",
    "            \"f1\": {},\n",
    "        },\n",
    "        \"qwen\": {\n",
    "            \"whole_accuracy\": 0,\n",
    "            \"precision\": {},\n",
    "            \"recall\": {},\n",
    "            \"f1\": {},\n",
    "        }\n",
    "    }\n",
    "\n",
    "    for model in results[\"details\"]:\n",
    "        # Whole accuracy\n",
    "        scores[model][\"whole_accuracy\"] = sum([results[\"details\"][model][role][\"true_positive\"] for role in results[\"details\"][model]]) / sum([results[\"details\"][model][role][\"true_positive\"] + results[\"details\"][model][role][\"false_positive\"] for role in results[\"details\"][model]]) if sum([results[\"details\"][model][role][\"true_positive\"] + results[\"details\"][model][role][\"false_positive\"] for role in results[\"details\"][model]]) > 0 else 0\n",
    "\n",
    "        # Accuracy, Precision, Recall, F1 for each role\n",
    "        for role in results[\"details\"][model]:\n",
    "            true_positive = results[\"details\"][model][role][\"true_positive\"]\n",
    "            false_positive = results[\"details\"][model][role][\"false_positive\"]\n",
    "            false_negative = results[\"details\"][model][role][\"false_negative\"]\n",
    "\n",
    "            scores[model][\"precision\"][role] = true_positive / (true_positive + false_positive) if true_positive + false_positive > 0 else 0\n",
    "            scores[model][\"recall\"][role] = true_positive / (true_positive + false_negative) if true_positive + false_negative > 0 else 0\n",
    "            scores[model][\"f1\"][role] = 2 * (scores[model][\"precision\"][role] * scores[model][\"recall\"][role]) / (scores[model][\"precision\"][role] + scores[model][\"recall\"][role]) if scores[model][\"precision\"][role] + scores[model][\"recall\"][role] > 0 else 0\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nbWyYbQRq1bo",
    "outputId": "74f9d631-8aa2-49d2-a3fe-7415543a0bc2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing hannarubbercompany.com.json...\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: decorative\n",
      "Predicted role (GPT-4o): decorative\n",
      "Correct role: decorative\n",
      "Predicted role (GPT-4o): decorative\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: decorative\n",
      "Predicted role (GPT-4o): decorative\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Processing deckorum.co.uk.json...\n",
      "Correct role: informative\n",
      "Predicted role (GPT-4o): functional\n",
      "Processing femiclear.com.json...\n",
      "Correct role: informative\n",
      "Predicted role (GPT-4o): decorative\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: informative\n",
      "Predicted role (GPT-4o): decorative\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: decorative\n",
      "Predicted role (GPT-4o): informative\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: decorative\n",
      "Predicted role (GPT-4o): informative\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: informative\n",
      "Predicted role (GPT-4o): informative\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Processing six100okc.com.json...\n",
      "Correct role: functional\n",
      "Error code: 400 - {'error': {'message': 'Timeout while downloading http://six100okc.com/TemplateResources/Global/images/rplogo-white.png.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_image_url'}}\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Processing acute-firstaid.co.uk.json...\n",
      "Correct role: functional\n",
      "Error code: 400 - {'error': {'message': 'Error while downloading https://scontent-ord5-1.cdninstagram.com/v/t51.2885-15/436658091_2148106745536888_1114436654605773733_n.jpg?_nc_cat=108&ccb=1-7&_nc_sid=18de74&_nc_ohc=9g9HXwnUBr4Q7kNvgGKRm6c&_nc_ht=scontent-ord5-1.cdninstagram.com&edm=ANo9K5cEAAAA&oh=00_AYBeDOUH0FbY2ACX0G8WRMQpowAyi3dSw4r17PIOzLjuhw&oe=66C3B19D.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_image_url'}}\n",
      "Correct role: functional\n",
      "Error code: 400 - {'error': {'message': 'Error while downloading https://scontent-ord5-1.cdninstagram.com/v/t51.2885-15/449209065_1029753418487280_8265964229199352961_n.jpg?_nc_cat=101&ccb=1-7&_nc_sid=18de74&_nc_ohc=3zupQU1SoN0Q7kNvgHtlcZT&_nc_ht=scontent-ord5-1.cdninstagram.com&edm=ANo9K5cEAAAA&oh=00_AYCB4hE9gglZsmojvQNr0fXp5KvesJkGhYgZ95X2O-N_bA&oe=66C39536.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_image_url'}}\n",
      "Correct role: functional\n",
      "Error code: 400 - {'error': {'message': 'Error while downloading https://scontent-ord5-1.cdninstagram.com/v/t51.2885-15/445587705_324818603970389_5621992654525520705_n.jpg?_nc_cat=101&ccb=1-7&_nc_sid=18de74&_nc_ohc=Lrpcf7vguN4Q7kNvgG3wOSy&_nc_ht=scontent-ord5-1.cdninstagram.com&edm=ANo9K5cEAAAA&oh=00_AYBDv1prsSDB5EnKNIbpZylZOSTClQnGeMtnfLELqAySAA&oe=66C3AD59.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_image_url'}}\n",
      "Correct role: functional\n",
      "Error code: 400 - {'error': {'message': 'Error while downloading https://scontent-ord5-1.cdninstagram.com/v/t51.2885-15/436222519_962520585412381_7537594217573234630_n.jpg?_nc_cat=106&ccb=1-7&_nc_sid=18de74&_nc_ohc=6VZR2JsSTEwQ7kNvgHN18mU&_nc_ht=scontent-ord5-1.cdninstagram.com&edm=ANo9K5cEAAAA&oh=00_AYA55QYCh_-s-knvfd4Ew7jiZkvk5prcOx9IEQKQTPxlQg&oe=66C3A525.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_image_url'}}\n",
      "Correct role: complex\n",
      "Predicted role (GPT-4o): complex\n",
      "Correct role: functional\n",
      "Error code: 400 - {'error': {'message': 'Error while downloading https://scontent-ord5-2.cdninstagram.com/v/t51.2885-15/428184688_763359735302499_7653264278065697193_n.jpg?_nc_cat=100&ccb=1-7&_nc_sid=18de74&_nc_ohc=gL7mUHlJNyEQ7kNvgF3Ehlu&_nc_ht=scontent-ord5-2.cdninstagram.com&edm=ANo9K5cEAAAA&oh=00_AYBc3JC7KwGEHdTyBVKkVZwntZhd_rmGkSOXkTUf2AJKaw&oe=66C3B793.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_image_url'}}\n",
      "Correct role: functional\n",
      "Error code: 400 - {'error': {'message': 'Error while downloading https://scontent-ord5-2.cdninstagram.com/v/t51.2885-15/437590490_451135900908658_2232398160532121753_n.jpg?_nc_cat=100&ccb=1-7&_nc_sid=18de74&_nc_ohc=VWw6TKP6qQAQ7kNvgEbXug_&_nc_ht=scontent-ord5-2.cdninstagram.com&edm=ANo9K5cEAAAA&oh=00_AYDksHDkolzZ3UjWQfq4ESrK8gmynurCbWQCGDxc1ZF60Q&oe=66C3C17E.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_image_url'}}\n",
      "Correct role: functional\n",
      "Error code: 400 - {'error': {'message': 'Error while downloading https://scontent-ord5-1.cdninstagram.com/v/t51.2885-15/440757352_468249802306889_3840643560646656741_n.jpg?_nc_cat=108&ccb=1-7&_nc_sid=18de74&_nc_ohc=E5f7vTYETYQQ7kNvgFMk2ro&_nc_ht=scontent-ord5-1.cdninstagram.com&edm=ANo9K5cEAAAA&oh=00_AYAg0qtwMdivJR4oE_5JuW_Xt_oLF72yC_jjDpdf8DgAGQ&oe=66C3B8B6.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_image_url'}}\n",
      "Correct role: informative\n",
      "Predicted role (GPT-4o): complex\n",
      "Correct role: functional\n",
      "Error code: 400 - {'error': {'message': 'Error while downloading https://scontent-ord5-2.cdninstagram.com/v/t51.29350-15/447717638_1038045511076800_1686555759075030876_n.jpg?_nc_cat=102&ccb=1-7&_nc_sid=18de74&_nc_ohc=UivDmBS6SLcQ7kNvgEGats8&_nc_ht=scontent-ord5-2.cdninstagram.com&edm=ANo9K5cEAAAA&oh=00_AYC_oF6uDHZJ2OL9A0Fjr0i3FxHFpW-Mwu-n6bo1WvZUwA&oe=66C3A2FE.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_image_url'}}\n",
      "Processing changehealthcare.com.json...\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: decorative\n",
      "Error code: 400 - {'error': {'message': 'Error while downloading http://changehealthcare.com/_jcr_content/root/main-par/circular_slider/circularSliderItems/item1/mobileImage.coreimg.jpeg/1642108548176/who-we-help-short-mobile-2.jpeg.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_image_url'}}\n",
      "Correct role: decorative\n",
      "Error code: 400 - {'error': {'message': 'Error while downloading http://changehealthcare.com/_jcr_content/root/main-par/stats_tile/statsTilesItems/item1/image.coreimg.png/1695225045676/image-29.png.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_image_url'}}\n",
      "Correct role: decorative\n",
      "Error code: 400 - {'error': {'message': 'Error while downloading http://changehealthcare.com/_jcr_content/root/main-par/circular_slider/circularSliderItems/item1/desktopImage.coreimg.jpeg/1642108548110/who-we-help-short-2.jpeg.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_image_url'}}\n",
      "Correct role: decorative\n",
      "Error code: 400 - {'error': {'message': 'Error while downloading http://changehealthcare.com/content/dam/change-healthcare/corporate-site-2021/icons/asset-type-icons/Infographic_Dark.png.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_image_url'}}\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: decorative\n",
      "Error code: 400 - {'error': {'message': 'Error while downloading http://changehealthcare.com/_jcr_content/root/main-par/circular_slider/circularSliderItems/item2/desktopImage.coreimg.jpeg/1642108545310/who-we-help-short-3.jpeg.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_image_url'}}\n",
      "Correct role: decorative\n",
      "Predicted role (GPT-4o): decorative\n",
      "Correct role: decorative\n",
      "Error code: 400 - {'error': {'message': 'Error while downloading http://changehealthcare.com/content/dam/change-healthcare/corporate-site-2021/icons/asset-type-icons/Article_Dark.png.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_image_url'}}\n",
      "Correct role: decorative\n",
      "Error code: 400 - {'error': {'message': 'Error while downloading http://changehealthcare.com/_jcr_content/root/main-par/circular_slider/circularSliderItems/item3/mobileImage.coreimg.jpeg/1642108548176/who-we-help-short-mobile-2.jpeg.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_image_url'}}\n",
      "Correct role: decorative\n",
      "Error code: 400 - {'error': {'message': 'Error while downloading http://changehealthcare.com/_jcr_content/root/main-par/circular_slider/circularSliderItems/item0/mobileImage.coreimg.jpeg/1642108545117/who-we-help-short-mobile-1.jpeg.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_image_url'}}\n",
      "Correct role: decorative\n",
      "Error code: 400 - {'error': {'message': 'Error while downloading http://changehealthcare.com/_jcr_content/root/main-par/circular_slider/circularSliderItems/item0/desktopImage.coreimg.jpeg/1642108548240/who-we-help-short-1.jpeg.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_image_url'}}\n",
      "Correct role: decorative\n",
      "Error code: 400 - {'error': {'message': 'Error while downloading http://changehealthcare.com/_jcr_content/root/main-par/circular_slider/circularSliderItems/item2/mobileImage.coreimg.jpeg/1642108545230/who-we-help-short-mobile-3.jpeg.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_image_url'}}\n",
      "Correct role: decorative\n",
      "Error code: 400 - {'error': {'message': 'Error while downloading http://changehealthcare.com/content/dam/change-healthcare/corporate-site-2021/icons/asset-type-icons/eBook_Dark.png.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_image_url'}}\n",
      "Correct role: decorative\n",
      "Error code: 400 - {'error': {'message': 'Error while downloading http://changehealthcare.com/_jcr_content/root/main-par/circular_slider/circularSliderItems/item3/desktopImage.coreimg.jpeg/1642108548110/who-we-help-short-2.jpeg.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_image_url'}}\n",
      "Processing enguruapp.com.json...\n",
      "Correct role: decorative\n",
      "Predicted role (GPT-4o): decorative\n",
      "Correct role: informative\n",
      "Predicted role (GPT-4o): informative\n",
      "Correct role: decorative\n",
      "Predicted role (GPT-4o): decorative\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: informative\n",
      "Predicted role (GPT-4o): informative\n",
      "Correct role: decorative\n",
      "Predicted role (GPT-4o): decorative\n",
      "Correct role: decorative\n",
      "Predicted role (GPT-4o): decorative\n",
      "Correct role: decorative\n",
      "Predicted role (GPT-4o): decorative\n",
      "Correct role: decorative\n",
      "Predicted role (GPT-4o): decorative\n",
      "Correct role: informative\n",
      "Predicted role (GPT-4o): decorative\n",
      "Correct role: decorative\n",
      "Predicted role (GPT-4o): decorative\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): decorative\n",
      "Correct role: decorative\n",
      "Predicted role (GPT-4o): decorative\n",
      "Correct role: informative\n",
      "Predicted role (GPT-4o): informative\n",
      "Correct role: decorative\n",
      "Predicted role (GPT-4o): decorative\n",
      "Correct role: decorative\n",
      "Predicted role (GPT-4o): decorative\n",
      "Correct role: decorative\n",
      "Predicted role (GPT-4o): decorative\n",
      "Correct role: decorative\n",
      "Predicted role (GPT-4o): decorative\n",
      "Correct role: decorative\n",
      "Predicted role (GPT-4o): decorative\n",
      "Processing cancer.net.json...\n",
      "Processing gorbel.com.json...\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Processing ecsgroup.co.uk.json...\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Processing aeroinvestments.com.json...\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Processing bnbbosses.com.json...\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): complex\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: informative\n",
      "Predicted role (GPT-4o): complex\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): complex\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Processing weclapp.com.json...\n",
      "Correct role: complex\n",
      "Predicted role (GPT-4o): complex\n",
      "Correct role: decorative\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: complex\n",
      "Predicted role (GPT-4o): complex\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Error code: 400 - {'error': {'message': 'Error while downloading https://www.weclapp.com/en/wp-content/uploads/sites/5/2023/04/certificates-international-q423.png.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_image_url'}}\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: informative\n",
      "Predicted role (GPT-4o): informative\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Processing toptronic.com.json...\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Processing leonbrauer.com.json...\n",
      "Processing allcaresoftware.com.json...\n",
      "Correct role: informative\n",
      "Predicted role (GPT-4o): informative\n",
      "Correct role: informative\n",
      "Predicted role (GPT-4o): decorative\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: informative\n",
      "Predicted role (GPT-4o): informative\n",
      "Processing nuaire.com.json...\n",
      "Correct role: functional\n",
      "Error code: 400 - {'error': {'message': 'Timeout while downloading http://nuaire.com/-/media/Project/Nuaire/Public-Site/co2-incubators-350x233.jpg?h=200&iar=0&w=200&hash=F4C20C85F033A1BD0114A13581935637.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_image_url'}}\n",
      "Correct role: informative\n",
      "Predicted role (GPT-4o): informative\n",
      "Correct role: decorative\n",
      "Predicted role (GPT-4o): complex\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: informative\n",
      "Predicted role (GPT-4o): informative\n",
      "Correct role: decorative\n",
      "Predicted role (GPT-4o): complex\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: decorative\n",
      "Predicted role (GPT-4o): complex\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: informative\n",
      "Predicted role (GPT-4o): informative\n",
      "Correct role: informative\n",
      "Predicted role (GPT-4o): informative\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: informative\n",
      "Predicted role (GPT-4o): informative\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: informative\n",
      "Predicted role (GPT-4o): informative\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Processing buyfoundation.com.json...\n",
      "Correct role: functional\n",
      "Error code: 400 - {'error': {'message': 'Timeout while downloading http://buyfoundation.com/static/v9/media/images/third-party/v1/ad-choices-logo-11x12.png?r=1723645112000.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_image_url'}}\n",
      "Correct role: functional\n",
      "Error code: 400 - {'error': {'message': 'Timeout while downloading http://buyfoundation.com/static/v8/global/images/franchise-logos/auto/c/cadillac/white/117x80.png?r=1723577694000.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_image_url'}}\n",
      "Correct role: functional\n",
      "Error code: 400 - {'error': {'message': 'Timeout while downloading http://buyfoundation.com/static/v8/global/images/franchise-logos/auto/h/hyundai/white/183x125.png?r=1723577694000.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_image_url'}}\n",
      "Correct role: functional\n",
      "Error code: 400 - {'error': {'message': 'Timeout while downloading http://buyfoundation.com/static/v8/global/images/franchise-logos/auto/c/chevrolet/white/117x80.png?r=1723577694000.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_image_url'}}\n",
      "Correct role: functional\n",
      "Error code: 400 - {'error': {'message': 'Timeout while downloading http://buyfoundation.com/static/v8/global/images/franchise-logos/auto/k/kia/white/183x125.png?r=1723577694000.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_image_url'}}\n",
      "Processing ragerflooring.com.json...\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Error code: 400 - {'error': {'message': 'Error while downloading https://ragerflooring.com:443/-/media/abbey/membersiteimages/0168/custom/2023-10-new-pages/free-measure-cta.jpg.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_image_url'}}\n",
      "Correct role: informative\n",
      "Predicted role (GPT-4o): decorative\n",
      "Correct role: functional\n",
      "Error code: 400 - {'error': {'message': 'Error while downloading https://ragerflooring.com:443/-/media/abbey/membersiteimages/0168/custom/2023-10-new-pages/commercial-flooring-installation-cta.jpg.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_image_url'}}\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Error code: 400 - {'error': {'message': 'Error while downloading https://ragerflooring.com:443/-/media/abbey/membersiteimages/0168/custom/2023-10-new-pages/realtor-property-managers-cta.jpg.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_image_url'}}\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: informative\n",
      "Predicted role (GPT-4o): informative\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Error code: 400 - {'error': {'message': 'Error while downloading https://ragerflooring.com:443/-/media/abbey/membersiteimages/0168/custom/2023-10-new-pages/hardwood-restoration-cta.jpg.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_image_url'}}\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Error code: 400 - {'error': {'message': 'Error while downloading https://ragerflooring.com:443/-/media/abbey/membersiteimages/0168/custom/2023-10-new-pages/free-measure-cta.jpg.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_image_url'}}\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Error code: 400 - {'error': {'message': 'Error while downloading https://ragerflooring.com:443/-/media/abbey/membersiteimages/0168/custom/2023-10-new-pages/commercial-flooring-installation-cta.jpg.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_image_url'}}\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: decorative\n",
      "Predicted role (GPT-4o): decorative\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: informative\n",
      "Predicted role (GPT-4o): informative\n",
      "Correct role: informative\n",
      "Predicted role (GPT-4o): informative\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: informative\n",
      "Predicted role (GPT-4o): informative\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Error code: 400 - {'error': {'message': 'Error while downloading https://ragerflooring.com:443/-/media/abbey/membersiteimages/0168/custom/2023-10-new-pages/hardwood-restoration-cta.jpg.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_image_url'}}\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Error code: 400 - {'error': {'message': 'Error while downloading https://ragerflooring.com:443/-/media/abbey/membersiteimages/0168/custom/2023-10-new-pages/realtor-property-managers-cta.jpg.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_image_url'}}\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Processing livethetyler.com.json...\n",
      "Correct role: informative\n",
      "Predicted role (GPT-4o): informative\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Processing verrex.com.json...\n",
      "Correct role: decorative\n",
      "Predicted role (GPT-4o): decorative\n",
      "Correct role: decorative\n",
      "Predicted role (GPT-4o): decorative\n",
      "Processing popaball.co.uk.json...\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Processing cvtc.edu.json...\n",
      "Correct role: informative\n",
      "Predicted role (GPT-4o): functional\n",
      "Processing unifiedsupply.com.json...\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: informative\n",
      "Predicted role (GPT-4o): informative\n",
      "Correct role: informative\n",
      "Predicted role (GPT-4o): complex\n",
      "Processing ladymashaka.com.json...\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): informative\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Processing maeimd.com.json...\n",
      "Correct role: informative\n",
      "Predicted role (GPT-4o): informative\n",
      "Correct role: decorative\n",
      "Predicted role (GPT-4o): decorative\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: informative\n",
      "Predicted role (GPT-4o): informative\n",
      "Correct role: informative\n",
      "Predicted role (GPT-4o): informative\n",
      "Processing donutworrybehappy.eu.json...\n",
      "Correct role: informative\n",
      "Predicted role (GPT-4o): decorative\n",
      "Correct role: informative\n",
      "Predicted role (GPT-4o): informative\n",
      "Correct role: informative\n",
      "Predicted role (GPT-4o): decorative\n",
      "Correct role: informative\n",
      "Predicted role (GPT-4o): informative\n",
      "Correct role: informative\n",
      "Predicted role (GPT-4o): decorative\n",
      "Correct role: informative\n",
      "Predicted role (GPT-4o): decorative\n",
      "Correct role: informative\n",
      "Predicted role (GPT-4o): complex\n",
      "Processing advancedhomehealth.com.json...\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: informative\n",
      "Predicted role (GPT-4o): informative\n",
      "Correct role: informative\n",
      "Predicted role (GPT-4o): decorative\n",
      "Correct role: informative\n",
      "Predicted role (GPT-4o): informative\n",
      "Correct role: informative\n",
      "Predicted role (GPT-4o): decorative\n",
      "Correct role: informative\n",
      "Predicted role (GPT-4o): informative\n",
      "Processing theinkspot.com.au.json...\n",
      "Processing predictmeso.com.json...\n",
      "Processing crucialpointllc.com.json...\n",
      "Processing caudit.edu.au.json...\n",
      "Processing jessekellyshow.com.json...\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: informative\n",
      "Predicted role (GPT-4o): decorative\n",
      "Processing tacita.io.json...\n",
      "Processing summitir.com.json...\n",
      "Correct role: informative\n",
      "Predicted role (GPT-4o): informative\n",
      "Correct role: informative\n",
      "Predicted role (GPT-4o): informative\n",
      "Correct role: informative\n",
      "Predicted role (GPT-4o): informative\n",
      "Correct role: decorative\n",
      "Predicted role (GPT-4o): informative\n",
      "Correct role: decorative\n",
      "Predicted role (GPT-4o): decorative\n",
      "Correct role: decorative\n",
      "Predicted role (GPT-4o): decorative\n",
      "Correct role: decorative\n",
      "Predicted role (GPT-4o): informative\n",
      "Correct role: decorative\n",
      "Predicted role (GPT-4o): decorative\n",
      "Correct role: decorative\n",
      "Predicted role (GPT-4o): decorative\n",
      "Correct role: decorative\n",
      "Predicted role (GPT-4o): informative\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: decorative\n",
      "Predicted role (GPT-4o): decorative\n",
      "Correct role: decorative\n",
      "Predicted role (GPT-4o): decorative\n",
      "Processing themotherhoodcenter.com.json...\n",
      "Processing ludacreative.com.au.json...\n",
      "Correct role: informative\n",
      "Predicted role (GPT-4o): informative\n",
      "Correct role: informative\n",
      "Predicted role (GPT-4o): decorative\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: informative\n",
      "Predicted role (GPT-4o): informative\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): informative\n",
      "Correct role: informative\n",
      "Predicted role (GPT-4o): decorative\n",
      "Correct role: informative\n",
      "Predicted role (GPT-4o): decorative\n",
      "Correct role: informative\n",
      "Predicted role (GPT-4o): informative\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: informative\n",
      "Predicted role (GPT-4o): decorative\n",
      "Correct role: informative\n",
      "Predicted role (GPT-4o): decorative\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: informative\n",
      "Predicted role (GPT-4o): informative\n",
      "Correct role: informative\n",
      "Predicted role (GPT-4o): informative\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): informative\n",
      "Processing forteracu.com.json...\n",
      "Processing womeninlawleaders.com.json...\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Processing averoadvisors.com.json...\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Processing masonrycap.com.json...\n",
      "Processing dimanche.gr.json...\n",
      "Correct role: informative\n",
      "Predicted role (GPT-4o): informative\n",
      "Correct role: informative\n",
      "Predicted role (GPT-4o): decorative\n",
      "Correct role: informative\n",
      "Predicted role (GPT-4o): decorative\n",
      "Correct role: informative\n",
      "Predicted role (GPT-4o): informative\n",
      "Processing shootfordetails.com.json...\n",
      "Correct role: informative\n",
      "Predicted role (GPT-4o): informative\n",
      "Correct role: informative\n",
      "Predicted role (GPT-4o): complex\n",
      "Correct role: informative\n",
      "Predicted role (GPT-4o): informative\n",
      "Correct role: informative\n",
      "Predicted role (GPT-4o): informative\n",
      "Correct role: informative\n",
      "Predicted role (GPT-4o): informative\n",
      "Processing zubi.co.nz.json...\n",
      "Correct role: informative\n",
      "Predicted role (GPT-4o): informative\n",
      "Correct role: informative\n",
      "Predicted role (GPT-4o): informative\n",
      "Correct role: informative\n",
      "Predicted role (GPT-4o): informative\n",
      "Correct role: complex\n",
      "Predicted role (GPT-4o): complex\n",
      "Correct role: informative\n",
      "Predicted role (GPT-4o): informative\n",
      "Correct role: informative\n",
      "Predicted role (GPT-4o): informative\n",
      "Correct role: informative\n",
      "Predicted role (GPT-4o): informative\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: informative\n",
      "Predicted role (GPT-4o): informative\n",
      "Correct role: informative\n",
      "Predicted role (GPT-4o): informative\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: informative\n",
      "Predicted role (GPT-4o): informative\n",
      "Correct role: informative\n",
      "Predicted role (GPT-4o): informative\n",
      "Correct role: informative\n",
      "Predicted role (GPT-4o): informative\n",
      "Correct role: informative\n",
      "Predicted role (GPT-4o): informative\n",
      "Correct role: informative\n",
      "Predicted role (GPT-4o): informative\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: informative\n",
      "Predicted role (GPT-4o): informative\n",
      "Correct role: complex\n",
      "Predicted role (GPT-4o): complex\n",
      "Correct role: informative\n",
      "Predicted role (GPT-4o): informative\n",
      "Correct role: informative\n",
      "Predicted role (GPT-4o): text\n",
      "Correct role: informative\n",
      "Predicted role (GPT-4o): informative\n",
      "Correct role: informative\n",
      "Predicted role (GPT-4o): informative\n",
      "Correct role: informative\n",
      "Predicted role (GPT-4o): text\n",
      "Correct role: complex\n",
      "Predicted role (GPT-4o): complex\n",
      "Correct role: informative\n",
      "Predicted role (GPT-4o): informative\n",
      "Correct role: informative\n",
      "Predicted role (GPT-4o): informative\n",
      "Correct role: informative\n",
      "Predicted role (GPT-4o): informative\n",
      "Correct role: informative\n",
      "Predicted role (GPT-4o): text\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: informative\n",
      "Predicted role (GPT-4o): informative\n",
      "Processing ram-digital.co.uk.json...\n",
      "Processing orderatdiscount.com.json...\n",
      "Processing eventnook.com.json...\n",
      "Correct role: complex\n",
      "Predicted role (GPT-4o): complex\n",
      "Correct role: informative\n",
      "Predicted role (GPT-4o): informative\n",
      "Correct role: informative\n",
      "Predicted role (GPT-4o): informative\n",
      "Correct role: informative\n",
      "Predicted role (GPT-4o): informative\n",
      "Correct role: informative\n",
      "Predicted role (GPT-4o): informative\n",
      "Correct role: complex\n",
      "Predicted role (GPT-4o): complex\n",
      "Correct role: informative\n",
      "Predicted role (GPT-4o): informative\n",
      "Correct role: informative\n",
      "Predicted role (GPT-4o): informative\n",
      "Correct role: complex\n",
      "Predicted role (GPT-4o): complex\n",
      "Correct role: informative\n",
      "Predicted role (GPT-4o): informative\n",
      "Correct role: complex\n",
      "Predicted role (GPT-4o): complex\n",
      "Correct role: complex\n",
      "Predicted role (GPT-4o): complex\n",
      "Correct role: complex\n",
      "Predicted role (GPT-4o): complex\n",
      "Correct role: informative\n",
      "Predicted role (GPT-4o): informative\n",
      "Correct role: complex\n",
      "Predicted role (GPT-4o): complex\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: informative\n",
      "Predicted role (GPT-4o): informative\n",
      "Correct role: informative\n",
      "Predicted role (GPT-4o): informative\n",
      "Correct role: informative\n",
      "Predicted role (GPT-4o): informative\n",
      "Correct role: informative\n",
      "Predicted role (GPT-4o): informative\n",
      "Correct role: informative\n",
      "Predicted role (GPT-4o): complex\n",
      "Correct role: informative\n",
      "Predicted role (GPT-4o): informative\n",
      "Correct role: informative\n",
      "Predicted role (GPT-4o): informative\n",
      "Correct role: decorative\n",
      "Predicted role (GPT-4o): informative\n",
      "Correct role: informative\n",
      "Predicted role (GPT-4o): informative\n",
      "Processing royaleastvw.com.json...\n",
      "Correct role: functional\n",
      "Error code: 400 - {'error': {'message': 'Timeout while downloading http://royaleastvw.com/static/v8/global/images/franchise-logos/auto/v/volkswagen/white/183x125.png?r=1723577694000.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_image_url'}}\n",
      "Processing chrispricerealty.com.json...\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Processing stockcharts.com-freecharts-historical-marketindexes.html.json...\n",
      "Correct role: complex\n",
      "Predicted role (GPT-4o): informative\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: complex\n",
      "Predicted role (GPT-4o): complex\n",
      "Correct role: complex\n",
      "Predicted role (GPT-4o): complex\n",
      "Correct role: complex\n",
      "Predicted role (GPT-4o): complex\n",
      "Correct role: complex\n",
      "Predicted role (GPT-4o): complex\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: complex\n",
      "Predicted role (GPT-4o): complex\n",
      "Correct role: complex\n",
      "Predicted role (GPT-4o): complex\n",
      "Correct role: complex\n",
      "Predicted role (GPT-4o): complex\n",
      "Correct role: complex\n",
      "Predicted role (GPT-4o): complex\n",
      "Correct role: complex\n",
      "Predicted role (GPT-4o): text\n",
      "Correct role: complex\n",
      "Predicted role (GPT-4o): complex\n",
      "Correct role: complex\n",
      "Predicted role (GPT-4o): complex\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: complex\n",
      "Predicted role (GPT-4o): complex\n",
      "Correct role: complex\n",
      "Predicted role (GPT-4o): complex\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: complex\n",
      "Predicted role (GPT-4o): complex\n",
      "Correct role: complex\n",
      "Predicted role (GPT-4o): complex\n",
      "Correct role: complex\n",
      "Predicted role (GPT-4o): complex\n",
      "Correct role: complex\n",
      "Predicted role (GPT-4o): complex\n",
      "Correct role: complex\n",
      "Predicted role (GPT-4o): complex\n",
      "Correct role: complex\n",
      "Predicted role (GPT-4o): complex\n",
      "Processing tapinfluence.com.json...\n",
      "Processing cwuk.com.json...\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: decorative\n",
      "Predicted role (GPT-4o): decorative\n",
      "Correct role: informative\n",
      "Predicted role (GPT-4o): decorative\n",
      "Correct role: decorative\n",
      "Predicted role (GPT-4o): decorative\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: decorative\n",
      "Predicted role (GPT-4o): decorative\n",
      "Correct role: decorative\n",
      "Predicted role (GPT-4o): decorative\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Correct role: functional\n",
      "Predicted role (GPT-4o): functional\n",
      "Processing chryssies.com.json...\n",
      "Total images processed: 453\n",
      "Results: {'total_images': 453, 'details': {'llama': {'informative': {'true_positive': 0, 'false_positive': 0, 'false_negative': 0}, 'decorative': {'true_positive': 0, 'false_positive': 0, 'false_negative': 0}, 'functional': {'true_positive': 0, 'false_positive': 0, 'false_negative': 0}, 'complex': {'true_positive': 0, 'false_positive': 0, 'false_negative': 0}}, 'gpt-4o': {'informative': {'true_positive': 77, 'false_positive': 10, 'false_negative': 31}, 'decorative': {'true_positive': 31, 'false_positive': 21, 'false_negative': 10}, 'functional': {'true_positive': 228, 'false_positive': 3, 'false_negative': 6}, 'complex': {'true_positive': 31, 'false_positive': 11, 'false_negative': 2}}, 'gpt-4o-mini': {'informative': {'true_positive': 0, 'false_positive': 0, 'false_negative': 0}, 'decorative': {'true_positive': 0, 'false_positive': 0, 'false_negative': 0}, 'functional': {'true_positive': 0, 'false_positive': 0, 'false_negative': 0}, 'complex': {'true_positive': 0, 'false_positive': 0, 'false_negative': 0}}, 'qwen': {'informative': {'true_positive': 0, 'false_positive': 0, 'false_negative': 0}, 'decorative': {'true_positive': 0, 'false_positive': 0, 'false_negative': 0}, 'functional': {'true_positive': 0, 'false_positive': 0, 'false_negative': 0}, 'complex': {'true_positive': 0, 'false_positive': 0, 'false_negative': 0}}}}\n",
      "Scores: {'llama': {'whole_accuracy': 0, 'precision': {'informative': 0, 'decorative': 0, 'functional': 0, 'complex': 0}, 'recall': {'informative': 0, 'decorative': 0, 'functional': 0, 'complex': 0}, 'f1': {'informative': 0, 'decorative': 0, 'functional': 0, 'complex': 0}}, 'gpt-4o': {'whole_accuracy': 0.8907766990291263, 'precision': {'informative': 0.8850574712643678, 'decorative': 0.5961538461538461, 'functional': 0.987012987012987, 'complex': 0.7380952380952381}, 'recall': {'informative': 0.7129629629629629, 'decorative': 0.7560975609756098, 'functional': 0.9743589743589743, 'complex': 0.9393939393939394}, 'f1': {'informative': 0.7897435897435897, 'decorative': 0.6666666666666667, 'functional': 0.9806451612903225, 'complex': 0.8266666666666667}}, 'gpt-4o-mini': {'whole_accuracy': 0, 'precision': {'informative': 0, 'decorative': 0, 'functional': 0, 'complex': 0}, 'recall': {'informative': 0, 'decorative': 0, 'functional': 0, 'complex': 0}, 'f1': {'informative': 0, 'decorative': 0, 'functional': 0, 'complex': 0}}, 'qwen': {'whole_accuracy': 0, 'precision': {'informative': 0, 'decorative': 0, 'functional': 0, 'complex': 0}, 'recall': {'informative': 0, 'decorative': 0, 'functional': 0, 'complex': 0}, 'f1': {'informative': 0, 'decorative': 0, 'functional': 0, 'complex': 0}}}\n"
     ]
    }
   ],
   "source": [
    "results = {\n",
    "    \"total_images\": 0,\n",
    "    \"details\": {\n",
    "        \"llama\" : {\n",
    "            \"informative\": {\"true_positive\": 0, \"false_positive\": 0, \"false_negative\": 0},\n",
    "            \"decorative\": {\"true_positive\": 0, \"false_positive\": 0, \"false_negative\": 0},\n",
    "            \"functional\": {\"true_positive\": 0, \"false_positive\": 0, \"false_negative\": 0},\n",
    "            \"complex\": {\"true_positive\": 0, \"false_positive\": 0, \"false_negative\": 0}\n",
    "        },\n",
    "        \"gpt-4o\" : {\n",
    "            \"informative\": {\"true_positive\": 0, \"false_positive\": 0, \"false_negative\": 0},\n",
    "            \"decorative\": {\"true_positive\": 0, \"false_positive\": 0, \"false_negative\": 0},\n",
    "            \"functional\": {\"true_positive\": 0, \"false_positive\": 0, \"false_negative\": 0},\n",
    "            \"complex\": {\"true_positive\": 0, \"false_positive\": 0, \"false_negative\": 0}\n",
    "        },\n",
    "        \"gpt-4o-mini\" : {\n",
    "            \"informative\": {\"true_positive\": 0, \"false_positive\": 0, \"false_negative\": 0},\n",
    "            \"decorative\": {\"true_positive\": 0, \"false_positive\": 0, \"false_negative\": 0},\n",
    "            \"functional\": {\"true_positive\": 0, \"false_positive\": 0, \"false_negative\": 0},\n",
    "            \"complex\": {\"true_positive\": 0, \"false_positive\": 0, \"false_negative\": 0}\n",
    "        },\n",
    "        \"qwen\" : {\n",
    "            \"informative\": {\"true_positive\": 0, \"false_positive\": 0, \"false_negative\": 0},\n",
    "            \"decorative\": {\"true_positive\": 0, \"false_positive\": 0, \"false_negative\": 0},\n",
    "            \"functional\": {\"true_positive\": 0, \"false_positive\": 0, \"false_negative\": 0},\n",
    "            \"complex\": {\"true_positive\": 0, \"false_positive\": 0, \"false_negative\": 0}\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "total_images = 0\n",
    "\n",
    "for filename in os.listdir(json_dir):\n",
    "    if total_images >= NUMBER_OF_IMAGES:\n",
    "        break\n",
    "\n",
    "    if filename.endswith(\".json\") and filename != \"aquapure-dicorium.com.json\" and filename != \"output.json\":\n",
    "        try:\n",
    "            # Read the JSON file\n",
    "            with open(os.path.join(json_dir, filename), \"r\") as file:\n",
    "                data = json.load(file)\n",
    "\n",
    "            print(f\"Processing {filename}...\")\n",
    "\n",
    "            # Extract the image link and textual context from the JSON data\n",
    "            whole_text = data[\"text\"]\n",
    "            sub_images = data[\"images\"]\n",
    "\n",
    "            for image in sub_images:\n",
    "                try:\n",
    "                    if image[\"role\"] != \"informative\" and image[\"role\"] != \"decorative\" and image[\"role\"] != \"functional\" and image[\"role\"] != \"complex\":\n",
    "                        continue\n",
    "\n",
    "                    if total_images >= NUMBER_OF_IMAGES:\n",
    "                        break\n",
    "\n",
    "                    total_images += 1\n",
    "                    results[\"total_images\"] += 1\n",
    "\n",
    "                    print(\"Correct role:\", image[\"role\"])\n",
    "\n",
    "                    # try:\n",
    "                    #     llama_answer = determine_role_llama(image).strip().lower().replace(\".\", \"\")\n",
    "                    #     print(\"Predicted role (Llama):\", llama_answer)\n",
    "                    #     if llama_answer == image[\"role\"]:\n",
    "                    #         results[\"details\"][\"llama\"][image[\"role\"]][\"true_positive\"] += 1\n",
    "                    #     else:\n",
    "                    #         results[\"details\"][\"llama\"][image[\"role\"]][\"false_negative\"] += 1\n",
    "                    #         if llama_answer in results[\"details\"][\"llama\"]:\n",
    "                    #             results[\"details\"][\"llama\"][llama_answer][\"false_positive\"] += 1\n",
    "                    # except Exception as e:\n",
    "                    #     print(str(e))\n",
    "\n",
    "\n",
    "                    # try:\n",
    "                    #     qwen_answer = determine_role_qwen_2b(image).strip().lower().replace(\".\", \"\")\n",
    "                    #     print(\"Predicted role (Qwen):\", qwen_answer)\n",
    "                    #     if qwen_answer == image[\"role\"]:\n",
    "                    #         results[\"details\"][\"qwen\"][image[\"role\"]][\"true_positive\"] += 1\n",
    "                    #     else:\n",
    "                    #         results[\"details\"][\"qwen\"][image[\"role\"]][\"false_negative\"] += 1\n",
    "                    #         if qwen_answer in results[\"details\"][\"qwen\"]:\n",
    "                    #             results[\"details\"][\"qwen\"][qwen_answer][\"false_positive\"] += 1\n",
    "                    # except Exception as e:\n",
    "                    #     print(str(e))\n",
    "\n",
    "\n",
    "                    try:\n",
    "                        gpt_4o_answer = determine_role_gpt_4o(image).strip().lower().replace(\".\", \"\")\n",
    "                        print(\"Predicted role (GPT-4o):\", gpt_4o_answer)\n",
    "                        if gpt_4o_answer == image[\"role\"]:\n",
    "                            results[\"details\"][\"gpt-4o\"][image[\"role\"]][\"true_positive\"] += 1\n",
    "                        else:\n",
    "                            results[\"details\"][\"gpt-4o\"][image[\"role\"]][\"false_negative\"] += 1\n",
    "                            if gpt_4o_answer in results[\"details\"][\"gpt-4o\"]:\n",
    "                                results[\"details\"][\"gpt-4o\"][gpt_4o_answer][\"false_positive\"] += 1\n",
    "                    except Exception as e:\n",
    "                        print(str(e))\n",
    "\n",
    "\n",
    "                    # try:\n",
    "                    #     gpt_4o_mini_answer = determine_role_gpt_4o_mini(image).strip().lower().replace(\".\", \"\")\n",
    "                    #     print(\"Predicted role (GPT-4o Mini):\", gpt_4o_mini_answer)\n",
    "                    #     if gpt_4o_mini_answer == image[\"role\"]:\n",
    "                    #         results[\"details\"][\"gpt-4o-mini\"][image[\"role\"]][\"true_positive\"] += 1\n",
    "                    #     else:\n",
    "                    #         results[\"details\"][\"gpt-4o-mini\"][image[\"role\"]][\"false_negative\"] += 1\n",
    "                    #         if gpt_4o_mini_answer in results[\"details\"][\"gpt-4o-mini\"]:\n",
    "                    #             results[\"details\"][\"gpt-4o-mini\"][gpt_4o_mini_answer][\"false_positive\"] += 1\n",
    "                    # except Exception as e:\n",
    "                    #     print(str(e))\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(str(e))\n",
    "\n",
    "            # Save the final state to a JSON file\n",
    "            with open(f\"output-gpt-4o-finetuned.json\", \"w\") as file:\n",
    "                json.dump({\n",
    "                    \"results\": results,\n",
    "                    \"scores\": calculate_scores(results)\n",
    "                }, file, indent=4)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(str(e))\n",
    "\n",
    "print(\"Total images processed:\", results[\"total_images\"])\n",
    "print(\"Results:\", results)\n",
    "print(\"Scores:\", calculate_scores(results))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
