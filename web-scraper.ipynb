{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's make a web scraper!\n",
    "\n",
    "## Goals: \n",
    "- Get data from a few websites, perhaps 100 images first, with the surrounding context (closest tag to them, class names, image names, parent tag, closest p for textual context and how far it is perhaps?)\n",
    "\n",
    "## How to:\n",
    "- Collect website names, just go for random 50 websites\n",
    "- Scrape them, analyze (wholly)\n",
    "- Decide which parts to take\n",
    "- Compile to json\n",
    "\n",
    "## To do:\n",
    "- Compile a list of websites with a more diverse role\n",
    "- Scrape parent tag\n",
    "- Scrape textual content\n",
    "- Compile to JSON or smth else"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: requests in /home/felinejtd/.local/lib/python3.10/site-packages (2.32.3)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/felinejtd/.local/lib/python3.10/site-packages (4.12.3)\n",
      "Requirement already satisfied: matplotlib in /home/felinejtd/.local/lib/python3.10/site-packages (3.9.0)\n",
      "Requirement already satisfied: numpy in /home/felinejtd/.local/lib/python3.10/site-packages (1.26.4)\n",
      "Requirement already satisfied: pandas in /home/felinejtd/.local/lib/python3.10/site-packages (2.2.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/felinejtd/.local/lib/python3.10/site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests) (1.26.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests) (2020.6.20)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/felinejtd/.local/lib/python3.10/site-packages (from beautifulsoup4) (2.5)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/felinejtd/.local/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: pillow>=8 in /home/felinejtd/.local/lib/python3.10/site-packages (from matplotlib) (10.3.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/felinejtd/.local/lib/python3.10/site-packages (from matplotlib) (24.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/felinejtd/.local/lib/python3.10/site-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/felinejtd/.local/lib/python3.10/site-packages (from matplotlib) (4.53.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/felinejtd/.local/lib/python3.10/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/felinejtd/.local/lib/python3.10/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/felinejtd/.local/lib/python3.10/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/felinejtd/.local/lib/python3.10/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install requests beautifulsoup4 matplotlib numpy pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "websites = [\n",
    "    # \"https://www.bbc.co.uk/news\",\n",
    "    # \"https://www.theguardian.com/uk\",\n",
    "    # \"https://www.telegraph.co.uk/\",\n",
    "    \"https://www.congress.gov/\",\n",
    "    # \"https://www.trendmicro.com/en_id/business.html\",\n",
    "    # \"https://www.independent.co.uk/\",\n",
    "    # \"https://www.mirror.co.uk/\",\n",
    "    # \"https://www.express.co.uk/\",\n",
    "    # \"https://www.dailymail.co.uk/\",\n",
    "    # \"https://www.thesun.co.uk/\",\n",
    "    # \"https://www.thetimes.co.uk/\",\n",
    "    # \"https://www.ft.com/\",\n",
    "    # \"https://www.economist.com/\",\n",
    "    # \"https://www.newstatesman.com/\",\n",
    "    # \"https://www.spectator.co.uk/\",\n",
    "    # \"https://www.huffingtonpost.co.uk/\",\n",
    "    # \"https://www.politico.eu/\",\n",
    "    # \"https://www.aljazeera.com/\",\n",
    "    # \"https://www.rt.com/\",\n",
    "    # \"https://www.dw.com/\",\n",
    "    # \"https://www.france24.com/\",\n",
    "    # \"https://www.euronews.com/\",\n",
    "    # \"https://www.bild.de/\",\n",
    "    # \"https://www.spiegel.de/\",\n",
    "    # \"https://www.faz.net/\",\n",
    "    # \"https://www.welt.de/\",\n",
    "    # \"https://www.taz.de/\",\n",
    "    # \"https://www.zeit.de/\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to label image manually\n",
    "\n",
    "import requests\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "def label_image(image_url, image_alt):\n",
    "    # Error handling\n",
    "    if not image_url.startswith(('http://', 'https://')):\n",
    "        image_url = urljoin(URL, image_url)\n",
    "    print(image_url)\n",
    "    # Download the image\n",
    "    image_res = requests.get(image_url)\n",
    "    # Display the image\n",
    "    image = Image.open(BytesIO(image_res.content))\n",
    "    plt.imshow(image)\n",
    "    plt.title(f'Current alt: {image_alt}')\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    # Manually label the data\n",
    "    # 1. Role\n",
    "    #   1: Informative (images that graphically represent concepts and information, typically pictures, photos, and illustrations.)\n",
    "    #   2: Decorative (the only purpose of an image is to add visual decoration to the page)\n",
    "    #   3: Functional (image used as a link or as a button, should describe the functionality of the link or button rather than the visual image)\n",
    "    #   4: Text (readable text)\n",
    "    #   5: Complex (diagrams or graphs)\n",
    "    role = input(\"Role of image (1-5): \")\n",
    "    # A shortcut to skip the image, input '0' for role\n",
    "    if (role == '0'):\n",
    "        return None\n",
    "    \n",
    "    # 2. New alt text, if previous alt text is not descriptive enough\n",
    "    new_alt = input(\"New alt text: \")\n",
    "\n",
    "    # 3. If the image has a readable text, input the text\n",
    "    text = input(\"Text in image (if any): \")\n",
    "\n",
    "    # 4. If the image has a known entity, input the entity\n",
    "    entity = input(\"Entity in image (if any, comma separated): \")\n",
    "\n",
    "    # Parse the data\n",
    "    if (role == '1'):\n",
    "        role = 'informative'\n",
    "    elif (role == '2'):\n",
    "        role = 'decorative'\n",
    "    elif (role == '3'):\n",
    "        role = 'functional'\n",
    "    elif (role == '4'):\n",
    "        role = 'text'\n",
    "    elif (role == '5'):\n",
    "        role = 'complex'\n",
    "    else:\n",
    "        role = 'unknown'\n",
    "\n",
    "    if (new_alt == ''):\n",
    "        new_alt = image_alt\n",
    "\n",
    "    entity = entity.split(',')\n",
    "\n",
    "    data = {\n",
    "        'role': role,\n",
    "        'new_alt': new_alt,\n",
    "        'text': text,\n",
    "        'entity': entity\n",
    "    }\n",
    "\n",
    "    return (data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening in existing browser session.\n"
     ]
    }
   ],
   "source": [
    "from io import BytesIO\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import json\n",
    "from IPython.display import clear_output\n",
    "import webbrowser\n",
    "\n",
    "for URL in websites:\n",
    "    # Open the URL in a new tab for reference while labelling\n",
    "    webbrowser.open_new_tab(URL)\n",
    "    # Get the HTML content of the page\n",
    "    page = requests.get(URL)\n",
    "    # Parse the HTML content\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "    # Find all 'img' tags\n",
    "    images = soup.find_all(\"img\")\n",
    "    # Remove duplicates\n",
    "    images = set(images)\n",
    "\n",
    "    for image in images:\n",
    "        try:\n",
    "            # Clear the output before displaying the next image to avoid an overly big notebook size\n",
    "            clear_output(wait=True)\n",
    "            # The 'src' attribute of the image\n",
    "            image_url = image[\"src\"]\n",
    "            # The 'alt' attribute of the image\n",
    "            image_alt = image.get(\"alt\", \"No alt attribute\")  # Use a default value if 'alt' is missing\n",
    "            # Label the image manually\n",
    "            data = label_image(image_url, image_alt)\n",
    "            # Write the data (iamage and labels) to a file\n",
    "            if data is not None:\n",
    "                print(data)\n",
    "            \n",
    "        except KeyError:\n",
    "            pass  # Skip images without 'src' or 'alt'\n",
    "        except requests.exceptions.MissingSchema:\n",
    "            pass  # Skip URLs without a schema\n",
    "\n",
    "# Step 4: Write the list to a file in JSON format\n",
    "# with open(\"news.json\", \"w\") as f:\n",
    "#     json.dump(images_info, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
      "\u001b[33mDEPRECATION: The HTML index page being used (https://download.pytorch.org/whl/torch_stable.html) is not a proper HTML 5 document. This is in violation of PEP 503 which requires these pages to be well-formed HTML 5 documents. Please reach out to the owners of this index page, and ask them to update this index page to a valid HTML 5 document. pip 22.2 will enforce this behaviour change. Discussion can be found at https://github.com/pypa/pip/issues/10825\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement torch==1.7.1+cpu (from versions: 1.11.0, 1.11.0+cpu, 1.11.0+cu102, 1.11.0+cu113, 1.11.0+cu115, 1.11.0+rocm4.3.1, 1.11.0+rocm4.5.2, 1.12.0, 1.12.0+cpu, 1.12.0+cu102, 1.12.0+cu113, 1.12.0+cu116, 1.12.0+rocm5.0, 1.12.0+rocm5.1.1, 1.12.1, 1.12.1+cpu, 1.12.1+cu102, 1.12.1+cu113, 1.12.1+cu116, 1.12.1+rocm5.0, 1.12.1+rocm5.1.1, 1.13.0, 1.13.0+cpu, 1.13.0+cu116, 1.13.0+cu117, 1.13.0+cu117.with.pypi.cudnn, 1.13.0+rocm5.1.1, 1.13.0+rocm5.2, 1.13.1, 1.13.1+cpu, 1.13.1+cu116, 1.13.1+cu117, 1.13.1+cu117.with.pypi.cudnn, 1.13.1+rocm5.1.1, 1.13.1+rocm5.2, 2.0.0, 2.0.0+cpu, 2.0.0+cpu.cxx11.abi, 2.0.0+cu117, 2.0.0+cu117.with.pypi.cudnn, 2.0.0+cu118, 2.0.0+rocm5.3, 2.0.0+rocm5.4.2, 2.0.1, 2.0.1+cpu, 2.0.1+cpu.cxx11.abi, 2.0.1+cu117, 2.0.1+cu117.with.pypi.cudnn, 2.0.1+cu118, 2.0.1+rocm5.3, 2.0.1+rocm5.4.2, 2.1.0, 2.1.0+cpu, 2.1.0+cpu.cxx11.abi, 2.1.0+cu118, 2.1.0+cu121, 2.1.0+cu121.with.pypi.cudnn, 2.1.0+rocm5.5, 2.1.0+rocm5.6, 2.1.1, 2.1.1+cpu, 2.1.1+cpu.cxx11.abi, 2.1.1+cu118, 2.1.1+cu121, 2.1.1+cu121.with.pypi.cudnn, 2.1.1+rocm5.5, 2.1.1+rocm5.6, 2.1.2, 2.1.2+cpu, 2.1.2+cpu.cxx11.abi, 2.1.2+cu118, 2.1.2+cu121, 2.1.2+cu121.with.pypi.cudnn, 2.1.2+rocm5.5, 2.1.2+rocm5.6, 2.2.0, 2.2.0+cpu, 2.2.0+cpu.cxx11.abi, 2.2.0+cu118, 2.2.0+cu121, 2.2.0+rocm5.6, 2.2.0+rocm5.7, 2.2.1, 2.2.1+cpu, 2.2.1+cpu.cxx11.abi, 2.2.1+cu118, 2.2.1+cu121, 2.2.1+rocm5.6, 2.2.1+rocm5.7, 2.2.2, 2.2.2+cpu, 2.2.2+cpu.cxx11.abi, 2.2.2+cu118, 2.2.2+cu121, 2.2.2+rocm5.6, 2.2.2+rocm5.7, 2.3.0, 2.3.0+cpu, 2.3.0+cpu.cxx11.abi, 2.3.0+cu118, 2.3.0+cu121, 2.3.0+rocm5.7, 2.3.0+rocm6.0, 2.3.1, 2.3.1+cpu, 2.3.1+cpu.cxx11.abi, 2.3.1+cu118, 2.3.1+cu121, 2.3.1+rocm5.7, 2.3.1+rocm6.0)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for torch==1.7.1+cpu\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Torch version: 2.3.1+cu121\n"
     ]
    }
   ],
   "source": [
    "# installing some dependencies, CLIP was released in PyTorch\n",
    "import subprocess\n",
    "\n",
    "# CUDA_version = [s for s in subprocess.check_output([\"nvcc\", \"--version\"]).decode(\"UTF-8\").split(\", \") if s.startswith(\"release\")][0].split(\" \")[-1]\n",
    "# print(\"CUDA version:\", CUDA_version)\n",
    "\n",
    "# if CUDA_version == \"10.0\":\n",
    "#     torch_version_suffix = \"+cu100\"\n",
    "# elif CUDA_version == \"10.1\":\n",
    "#     torch_version_suffix = \"+cu101\"\n",
    "# elif CUDA_version == \"10.2\":\n",
    "#     torch_version_suffix = \"\"\n",
    "# else:\n",
    "#     torch_version_suffix = \"+cu110\"\n",
    "\n",
    "%pip install torch==1.7.1+cpu torchvision==0.8.2+cpu -f https://download.pytorch.org/whl/torch_stable.html\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "print(\"Torch version:\", torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: gdown in /home/felinejtd/.local/lib/python3.10/site-packages (5.2.0)\n",
      "Collecting ftfy\n",
      "  Downloading ftfy-6.2.0-py3-none-any.whl (54 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.4/54.4 KB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: regex in /home/felinejtd/.local/lib/python3.10/site-packages (2024.5.15)\n",
      "Requirement already satisfied: tqdm in /home/felinejtd/.local/lib/python3.10/site-packages (from gdown) (4.66.4)\n",
      "Requirement already satisfied: filelock in /home/felinejtd/.local/lib/python3.10/site-packages (from gdown) (3.14.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/felinejtd/.local/lib/python3.10/site-packages (from gdown) (4.12.3)\n",
      "Requirement already satisfied: requests[socks] in /home/felinejtd/.local/lib/python3.10/site-packages (from gdown) (2.32.3)\n",
      "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /home/felinejtd/.local/lib/python3.10/site-packages (from ftfy) (0.2.13)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/felinejtd/.local/lib/python3.10/site-packages (from beautifulsoup4->gdown) (2.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/felinejtd/.local/lib/python3.10/site-packages (from requests[socks]->gdown) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests[socks]->gdown) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests[socks]->gdown) (1.26.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests[socks]->gdown) (2020.6.20)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /home/felinejtd/.local/lib/python3.10/site-packages (from requests[socks]->gdown) (1.7.1)\n",
      "Installing collected packages: ftfy\n",
      "Successfully installed ftfy-6.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install gdown ftfy regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'CLIP' already exists and is not an empty directory.\n",
      "CLIP dir is: /home/felinejtd/projects/itb/ta/image-alt-text-ai/CLIP\n"
     ]
    }
   ],
   "source": [
    "# clone the CLIP repository\n",
    "!git clone https://github.com/openai/CLIP.git\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "clip_dir = Path(\".\").absolute() / \"CLIP\"\n",
    "sys.path.append(str(clip_dir))\n",
    "print(f\"CLIP dir is: {clip_dir}\")\n",
    "\n",
    "import clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model dir: /home/felinejtd/.cache/clip\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained model\n",
    "import os\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, transform = clip.load(\"ViT-B/32\", device=device)\n",
    "print(f\"Model dir: {os.path.expanduser('~/.cache/clip')}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
